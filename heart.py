# -*- coding: utf-8 -*-
"""heart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AzvVA_ULzkBPx_xFzQHPkZaBQpEVzbR-
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings(action='ignore')
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.metrics import log_loss

train = pd.read_csv('Train.csv')
train.head()
test = pd.read_csv('Test.csv')

train.info()

train.describe()

train.isnull().sum()

sns.countplot(train.UnderRisk)

for c in train.columns :
    print(train[c].value_counts())

plt.figure(figsize=(20, 17))

sns.pairplot(train)

train.plot(x='Gender',y='Diabetes',kind = 'scatter')
plt.show()

X = train.iloc[:,:-1].values
y = train.iloc[:, 1].values
X[0]

from sklearn.preprocessing import LabelEncoder
labelencoder_X_1 = LabelEncoder()
y = labelencoder_X_1.fit_transform(y)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
classifier = Sequential([
    Dense(48, input_shape=(12,), activation='relu'),
    Dense(24, activation='relu'),
    Dense(12, activation='relu'),
    Dense(6, activation='relu'),
    Dense(3, activation='relu'),
    Dense(1, activation='sigmoid')
])

classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history=classifier.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=100, epochs=20)

classifier.summary()

sns.set()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)

# Accuracy plot
plt.plot(epochs, acc, color='green', label='Training Accuracy')
plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.figure()
# Loss plot
plt.plot(epochs, loss, color='green', label='Training Loss')
plt.plot(epochs, val_loss, color='red', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

y_pred = classifier.predict(X_test)
y_pred

y_pred1 = (y_pred > 0.5)
y_pred1

from sklearn.metrics import confusion_matrix, classification_report
cm = confusion_matrix(y_test, y_pred1)
print(cm)
print("accuracy is {}%".format(((cm[0][0] + cm[1][1])/57)*100))

def predict(model, X):
    pred = model.predict(X).flatten()
    pred[pred > 0.5] = 1
    pred[pred <= 0.5] = 0
    return pred

def plot_actual_vs_predicted(y_true,y_pred,title=None):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(7,7))
    sns.heatmap(cm, annot=True, fmt='g')

    #Labelling
    plt.xlabel("Actual")
    plt.ylabel("Predicted")
    plt.title(title)
    plt.show()
plot_actual_vs_predicted(y_test, y_pred1, 'Test Data Predictions')
print(classification_report(y_test, y_pred1))

classifier.save('cardiack risk prediction.h5')